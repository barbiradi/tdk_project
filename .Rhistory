perm_df <- data.frame(perm_diffs = perm_diffs)
ggplot(perm_df, aes(x = perm_diffs)) +
geom_histogram(bins = 40, alpha = 0.7) +
geom_vline(xintercept = obs_diff, color = "red", size = 1.2) +
labs(
title = "Permutation Test Null Distribution",
subtitle = paste("Observed difference =", round(obs_diff, 3)),
x = "Difference in means (BLM â€“ control)",
y = "Frequency"
)
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
p_value
perm_diffs <- replicate(n_sims, {df %>%
mutate(topic_perm = sample(topic)) %>%  # shuffle topic labels
summarise(
mean_topic     = mean(acceptance_delay[topic_perm == TRUE],  na.rm = TRUE),
mean_non_topic = mean(acceptance_delay[topic_perm == FALSE], na.rm = TRUE),
diff = mean_topic - mean_non_topic
) %>% pull(diff)
})
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
p_value
View(perm_df)
View(my_data_control_blm)
levels(my_data_control_blm$journal)
levels(my_data_blm2$journal)
df <- bind_rows(
my_data_blm2  %>% mutate(topic = TRUE),
my_data_control_blm %>% mutate(topic = FALSE)
)
topic_vec <- df$topic
delay_vec <- df$acceptance_delay
obs_diff <- mean(delay_vec[topic_vec == TRUE]) -
mean(delay_vec[topic_vec == FALSE])
set.seed(123)
n_sims <- 10000
perm_diffs <- replicate(n_sims, {
perm_topic <- sample(topic_vec)    # shuffled vector
mean(delay_vec[perm_topic == TRUE]) -
mean(delay_vec[perm_topic == FALSE])
})
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
p_value
mean(my_data_control_blm$acceptance_delay)
mean(my_data_blm2)
mean(my_data_blm2$acceptance_delay)
set.seed(123)
head(perm_diffs)
length(unique(perm_diffs))
# Create a clean unified dataset
df <- bind_rows(
my_data_blm2 %>% mutate(topic = TRUE),
my_data_control_blm %>% mutate(topic = FALSE)
)
# Force topic to a clean logical vector
topic_vec <- as.logical(df$topic)
# Force acceptance_delay to numeric vector
delay_vec <- as.numeric(df$acceptance_delay)
# Observed difference
obs_diff <- mean(delay_vec[topic_vec]) -
mean(delay_vec[!topic_vec])
obs_diff
set.seed(123)
n_sims <- 10000
perm_diffs <- replicate(n_sims, {
perm_topic <- sample(topic_vec)  # clean shuffle
mean(delay_vec[perm_topic]) - mean(delay_vec[!perm_topic])
})
# Permutation p-value
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
# Permutation p-value
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
# Permutation p-value
p_value <- mean(abs(perm_diffs) >= abs(obs_diff))
p_value
# Group sizes
nA <- nrow(my_data_blm2)
# Mean acceptance delay of the BLM-topic group
mean_A <- mean(my_data_blm2$acceptance_delay, na.rm = TRUE)
# Monte Carlo simulation
set.seed(123)
n_sims <- 10000
sim_means <- replicate(n_sims, {
my_data_control_blm %>%
sample_n(nA) %>%
summarise(m = mean(acceptance_delay, na.rm = TRUE)) %>%
pull(m)
})
# Monte Carlo p-value
p_value <- mean(sim_means >= mean_A)
p_value
sim_means <- replicate(n_sims, {
my_data_control_blm %>%
sample_n(nA) %>%
summarise(m = mean(acceptance_delay, na.rm = TRUE)) %>%
pull(m)
})
# Monte Carlo p-value
p_value <- mean(sim_means >= mean_A)
p_value
library(tidyverse)
library(dplyr)
library(readr)
install.packages("readxl")
library(readxl)
library(stringr)
library(ggplot2)
my_data = read_excel("C:/ELTE_ST/Additional research activity/TDK/tdk_project/tdk_data_cleaned.xlsx", sheet = 1)
my_data
view(my_data)
t.test(my_data$acceptance_delay, my_data1$acceptance_delay)
effectsize::cohens_d(my_data$acceptance_delay, my_data1$acceptance_delay, pooled_sd = TRUE, mu = 0, paired = FALSE)
class(my_data$acceptance_delay)
my_data_ai1_retracted = my_data_ai1 %>%
select(is_retracted) %>%
summary()
my_data_ai1_retracted
my_data_ai2_retracted = my_data_ai2 %>%
select(is_retracted) %>%
summary()
my_data_ai2_retracted
retracted_table = merge.data.frame(my_data_ai1_retracted, my_data_ai2_retracted)
retracted_table
patterns <- "\\bAI\\b|\\bAI-|ChatGPT|OpenAI|Generative AI|\\bLLM\\b|\\bLLMs\\b|Large language models|Chat GPT|GPT-3.5|GPT-4|\\bGPT\\b"
my_data_ai1 = my_data %>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate(article_date = as.Date(article_date))
threshold <- as.Date("2022-11-30") + median(my_data$acceptance_delay)
my_data_ai2 = my_data%>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
) %>%
filter(article_date > threshold)
my_data_control = my_data %>%
filter(article_date > threshold) %>%
semi_join(my_data_ai2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
))
my_data_ai2 = my_data_ai2 %>%
mutate(journal = factor(journal))
levels(my_data_ai2$journal)
library(dplyr)
library(readr)
library(readxl)
library(stringr)
library(ggplot2)
my_data = read_excel("C:/ELTE_ST/Additional research activity/TDK/tdk_project/tdk_data_cleaned.xlsx", sheet = 1)
my_data_ai1_retracted = my_data_ai1 %>%
select(is_retracted) %>%
summary()
my_data_ai1_retracted
patterns <- "\\bAI\\b|\\bAI-|ChatGPT|OpenAI|Generative AI|\\bLLM\\b|\\bLLMs\\b|Large language models|Chat GPT|GPT-3.5|GPT-4|\\bGPT\\b"
my_data_ai1 = my_data %>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate(article_date = as.Date(article_date))
threshold <- as.Date("2022-11-30") + median(my_data$acceptance_delay)
my_data_ai2 = my_data%>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
) %>%
filter(article_date > threshold)
my_data_control = my_data %>%
filter(article_date > threshold) %>%
semi_join(my_data_ai2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
))
my_data_ai2 = my_data_ai2 %>%
mutate(journal = factor(journal))
levels(my_data_ai2$journal)
my_data_control= my_data_control %>%
mutate(journal = factor(journal))
levels(my_data_control$journal)
my_data_control_sliced = my_data_control %>%
slice_sample(n = nrow(my_data_ai2)) %>%
arrange(article_date)
my_data_control_sliced %>%
ggplot()+
aes(x = article_date, y = acceptance_delay) %>%
geom_point()+
aes(x = article_date, y = acceptance_delay)+
geom_smooth()
my_data_ai2 %>%
ggplot()+
aes(x = article_date, y = acceptance_delay) %>%
geom_point()+
aes(x = article_date, y = acceptance_delay)+
geom_smooth()
t.test(my_data_ai2$acceptance_delay, my_data_control_sliced$acceptance_delay)
t.test(my_data_ai2$publication_delay, my_data_control_sliced$publication_delay)
patterns_2 = "\\bUS-election|Clinton|Donald Trump|2016-elections|presidential|president|Hillary|\\b2016 election\\b|2016-election|
voting|left party|right party|left wing|right wing|left-wing|right-wing|presidential|political|politics"
threshold_2 = as.Date("2019-12-12")
my_data_elections1 = my_data %>%
filter(
str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
) %>%
mutate(article_date = as.Date(article_date))
my_data_elections2 = my_data%>%
filter(
str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
) %>%
filter(article_date < threshold_2)
my_data_control_elections = my_data %>%
filter(article_date > threshold_2) %>%
semi_join(my_data_elections2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
))
my_data_elections2 = my_data_elections2 %>%
mutate(journal = factor(journal))
levels(my_data_ai2$journal)
my_data_control_elections= my_data_control_elections %>%
mutate(journal = factor(journal))
levels(my_data_control_elections$journal)
my_data_control_elections_sliced = my_data_control_elections %>%
slice_sample(n = nrow(my_data_elections2)) %>%
arrange(article_date)
t.test(my_data_elections2$acceptance_delay, my_data_control_elections_sliced$acceptance_delay)
t.test(my_data_elections2$publication_delay, my_data_control_elections_sliced$publication_delay)
patterns_3 = "black lives matter|blm|blacklivesmatter|\\bblm protest|blm movement|
george floyd|racial justice movement|racial justice protest|racial reckoning|
police brutality|police violence|systemic racism|institutional racism|
racial profiling|racialized violence|\\bracism|racial discrimination|racial inequality|black men|black people
african americans|african american|black youth|ethnic discrimination|racial/ethnic|\\bracial|other-race|black women|black student
|black children|black adolescent|black girl|black sexual minority|black american"
threshold_3 = as.Date("2020-05-25")
threshold_4 = as.Date("2023-01-01")
my_data_blm1 = my_data %>%
filter(
str_detect(title, regex(patterns_3, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_3, ignore_case = TRUE))
) %>%
mutate(article_date = as.Date(article_date))
my_data_blm2 = my_data%>%
filter(
str_detect(title, regex(patterns_3, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_3, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
) %>%
filter(article_date < threshold_4) %>%
filter(article_date > threshold_3)
my_data_control_blm = my_data %>%
filter (article_date > threshold_3) %>%
filter(article_date < threshold_4) %>%
semi_join(my_data_blm2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns_3, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_3, ignore_case = TRUE))
))
my_data_blm2 = my_data_blm2 %>%
mutate(journal = factor(journal))
levels(my_data_blm2$journal)
my_data_control_blm= my_data_control_blm %>%
mutate(journal = factor(journal))
levels(my_data_control_blm$journal)
my_data_control_blm_sliced = my_data_control_blm %>%
slice_sample(n = nrow(my_data_blm2)) %>%
arrange(article_date)
t.test(my_data_blm2$acceptance_delay, my_data_control_blm_sliced$acceptance_delay)
t.test(my_data_blm2$publication_delay, my_data_control_blm_sliced$publication_delay)
mean(my_data_control_blm$acceptance_delay)
mean(my_data_blm2$acceptance_delay)
my_data_control_blm = my_data %>%
filter (article_date > threshold_3) %>%
filter(article_date < threshold_4) %>%
semi_join(my_data_blm2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns_3, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_3, ignore_case = TRUE))
))
my_data_blm1 = my_data %>%
filter(
str_detect(title, regex(patterns_3, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_3, ignore_case = TRUE))
) %>%
mutate(article_date = as.Date(article_date))
threshold_3 = as.Date("2020-05-25")
threshold_4 = as.Date("2023-01-01")
my_data_blm1 = my_data %>%
filter(
str_detect(title, regex(patterns_3, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_3, ignore_case = TRUE))
) %>%
mutate(article_date = as.Date(article_date))
my_data_blm2 = my_data%>%
filter(
str_detect(title, regex(patterns_3, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_3, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
) %>%
filter(article_date < threshold_4) %>%
filter(article_date > threshold_3)
my_data_control_blm = my_data %>%
filter (article_date > threshold_3) %>%
filter(article_date < threshold_4) %>%
semi_join(my_data_blm2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns_3, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_3, ignore_case = TRUE))
))
my_data_control_blm = my_data %>%
filter (as.date(article_date) > threshold_3) %>%
filter(as.date(article_date) < threshold_4) %>%
semi_join(my_data_blm2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns_3, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_3, ignore_case = TRUE))
))
my_data_control_blm = my_data %>%
filter (as.Date(article_date) > threshold_3) %>%
filter(as.Date(article_date) < threshold_4) %>%
semi_join(my_data_blm2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns_3, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_3, ignore_case = TRUE))
))
my_data_blm2 = my_data_blm2 %>%
mutate(journal = factor(journal))
my_data_control_blm= my_data_control_blm %>%
mutate(journal = factor(journal))
levels(my_data_control_blm$journal)
my_data_control_blm_sliced = my_data_control_blm %>%
slice_sample(n = nrow(my_data_blm2)) %>%
arrange(article_date)
t.test(my_data_blm2$acceptance_delay, my_data_control_blm_sliced$acceptance_delay)
t.test(my_data_blm2$publication_delay, my_data_control_blm_sliced$publication_delay)
patterns_2 = "\\b2016 election|2016 presidential election|us 2016 election|
u\\.s\\. 2016 election|2016 us presidential|2016 u\\.s\\. presidential|Donald Trump|left wing|right wing|parties|
voting|"
threshold_2 = as.Date("2019-12-12")
my_data_elections1 = my_data %>%
filter(
str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
) %>%
mutate(article_date = as.Date(article_date))
my_data_elections2 = my_data%>%
filter(
str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
) %>%
filter(article_date < threshold_2)
my_data_control_elections = my_data %>%
filter(article_date > threshold_2) %>%
semi_join(my_data_elections2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
))
my_data_control_elections = my_data %>%
filter(as.Date(article_date > threshold_2)) %>%
semi_join(my_data_elections2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
))
my_data_control_elections = my_data %>%
filter(as.Date(article_date) > threshold_2) %>%
semi_join(my_data_elections2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
))
my_data_elections2 = my_data%>%
filter(
str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
) %>%
filter(article_date < threshold_2)
my_data_control_elections = my_data %>%
filter(as.Date(article_date) > threshold_2) %>%
semi_join(my_data_elections2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
))
my_data_control_elections = my_data %>%
filter(as.Date(article_date) < threshold_2) %>%
semi_join(my_data_elections2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
))
View(my_data_elections2)
patterns_2 = "\\b2016 election|2016 presidential election|us 2016 election|
u\\.s\\. 2016 election|2016 us presidential|2016 u\\.s\\. presidential|Donald Trump|left wing|right wing|parties|
voting"
threshold_2 = as.Date("2019-12-12")
my_data_elections1 = my_data %>%
filter(
str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
) %>%
mutate(article_date = as.Date(article_date))
my_data_elections2 = my_data%>%
filter(
str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
) %>%
filter(article_date < threshold_2)
my_data_control_elections = my_data %>%
filter(as.Date(article_date) < threshold_2) %>%
semi_join(my_data_elections2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
))
my_data_elections2 = my_data_elections2 %>%
mutate(journal = factor(journal))
levels(my_data_ai2$journal)
levels(my_data_elections2$journal)
levels(my_data_control_elections$journal)
my_data_control_elections= my_data_control_elections %>%
mutate(journal = factor(journal))
levels(my_data_control_elections$journal)
View(my_data_control_elections)
patterns_2 = "\\b2016 election|2016 presidential election|us 2016 election|
u\\.s\\. 2016 election|2016 us presidential|2016 u\\.s\\. presidential|Donald Trump|left wing|right wing|parties|
voting|Donald J. Trump|president|presidential"
threshold_2 = as.Date("2019-12-12")
my_data_elections1 = my_data %>%
filter(
str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
) %>%
mutate(article_date = as.Date(article_date))
my_data_elections2 = my_data%>%
filter(
str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
) %>%
filter(article_date < threshold_2)
my_data_control_elections = my_data %>%
filter(as.Date(article_date) < threshold_2) %>%
semi_join(my_data_elections2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
))
my_data_elections2 = my_data_elections2 %>%
mutate(journal = factor(journal))
levels(my_data_elections2$journal)
my_data_control_elections= my_data_control_elections %>%
mutate(journal = factor(journal))
patterns_2 = "\\b2016 election|2016 presidential election|us 2016 election|
u\\.s\\. 2016 election|2016 us presidential|2016 u\\.s\\. presidential|Donald Trump|left wing|right wing|parties|
voting|Donald J. Trump|president|presidential|political|politician|American election|United States election|US election"
threshold_2 = as.Date("2019-12-12")
my_data_elections1 = my_data %>%
filter(
str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
) %>%
mutate(article_date = as.Date(article_date))
my_data_elections2 = my_data%>%
filter(
str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
) %>%
filter(article_date < threshold_2)
my_data_control_elections = my_data %>%
filter(as.Date(article_date) < threshold_2) %>%
semi_join(my_data_elections2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns_2, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns_2, ignore_case = TRUE))
))
my_data_elections2 = my_data_elections2 %>%
mutate(journal = factor(journal))
levels(my_data_elections2$journal)
my_data_control_elections= my_data_control_elections %>%
mutate(journal = factor(journal))
levels(my_data_control_elections$journal)
View(my_data_elections2)
my_data_elections2 = my_data_elections2 %>%
mutate(journal = factor(journal))
levels(my_data_elections2$journal)
my_data_control_elections= my_data_control_elections %>%
mutate(journal = factor(journal))
levels(my_data_control_elections$journal)
my_data_control_elections_sliced = my_data_control_elections %>%
slice_sample(n = nrow(my_data_elections2)) %>%
arrange(article_date)
t.test(my_data_elections2$acceptance_delay, my_data_control_elections_sliced$acceptance_delay)
t.test(my_data_elections2$publication_delay, my_data_control_elections_sliced$publication_delay)
