my_data = read_excel("C:/ELTE_ST/Additional research activity/TDK/tdk_project/tdk_data_cleaned.xlsx", sheet = 1)
library(tidyverse)
library(dplyr)
library(readxl)
library(stringr)
library(ggplot2)
my_data = read_excel("C:/ELTE_ST/Additional research activity/TDK/tdk_project/tdk_data_cleaned.xlsx", sheet = 1)
my_data1 <- my_data %>%
filter(str_detect(title, regex("\\bAI\\b|\\bAI-\\b|ChatGPT|OpenAI|Generative AI|LLM|LLMs|Large language models")))
my_data_ai1 <- my_data %>%
mutate(
article_date_numeric = as.numeric(article_date),
article_date_date = as.Date(article_date)) %>%
filter((article_date > as.Date("2022-11-30") + median(my_data_ai1$acceptance_delay)))
my_data_ai1 <- my_data %>%
mutate(
article_date_numeric = as.numeric(article_date),
article_date_date = as.Date(article_date)) %>%
filter((article_date > as.Date("2022-11-30") + median(my_data_ai1$acceptance_delay)))
my_data_ai1 = my_data %>%
mutate(
article_date_numeric = as.numeric(article_date),
article_date_date = as.Date(article_date)) %>%
filter((article_date > as.Date("2022-11-30") + median(my_data_ai1$acceptance_delay)))
my_data_ai1 <- my_data %>%
mutate(
article_date = as.Date(article_date),
)
my_data_ai2 <- my_data1 %>%
mutate(
article_date = as.Date(article_date),
)
threshold <- as.Date("2022-11-30") + median(my_data$acceptance_delay)
my_data_ai1 <- my_data_ai1 %>%
filter(article_date > threshold)
my_data_ai2 = my_data_ai2 %>%
filter(article_date > threshold)
my_data_ai1 = my_data %>%
filter(str_detect(title, regex("\\bAI\\b|\\bAI-\\b|ChatGPT|OpenAI|Generative AI|LLM|LLMs|Large language models"))) filter(str_detect(keywords, regex("\\bAI\\b|\\bAI-\\b|ChatGPT|OpenAI|Generative AI|LLM|LLMs|Large language models")))
library(tidyverse)
library(dplyr)
library(readr)
library(readxl)
library(stringr)
library(ggplot2)
my_data = read_excel("C:/ELTE_ST/Additional research activity/TDK/tdk_project/tdk_data_cleaned.xlsx", sheet = 1)
my_data_ai1 <- my_data %>%
filter(str_detect(title, regex("\\bAI\\b|\\bAI-\\b|ChatGPT|OpenAI|Generative AI|LLM|LLMs|Large language models"))) filter(str_detect(keywords, regex("\\bAI\\b|\\bAI-\\b|ChatGPT|OpenAI|Generative AI|LLM|LLMs|Large language models"))) %>%
my_data_ai1 <- my_data %>%
filter(str_detect(title, regex("\\bAI\\b|\\bAI-\\b|ChatGPT|OpenAI|Generative AI|LLM|LLMs|Large language models"))) %>%
filter(str_detect(keywords, regex("\\bAI\\b|\\bAI-\\b|ChatGPT|OpenAI|Generative AI|LLM|LLMs|Large language models"))) %>%
mutate(
article_date = as.Date(article_date),
)
my_data_ai1 <- my_data %>%
filter(str_detect(title, regex("\\bAI\\b|\\bAI-\\b|ChatGPT|OpenAI|Generative AI|LLM|LLMs|Large language models"),
keywords, regex("\\bAI\\b|\\bAI-\\b|ChatGPT|OpenAI|Generative AI|LLM|LLMs|Large language models"))) %>%
mutate(
article_date = as.Date(article_date)
)
mutate(
article_date = as.Date(article_date)
)
View(my_data)
my_data_ai1 <- my_data %>%
filter(
str_detect(title, regex("\\bAI\\b|\\bAI-\\b|ChatGPT|OpenAI|Generative AI|LLM|LLMs|Large language models", ignore_case = TRUE)) |
str_detect(keywords, regex("\\bAI\\b|\\bAI-\\b|ChatGPT|OpenAI|Generative AI|LLM|LLMs|Large language models", ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
)
View(my_data_ai1)
my_data_ai1 = my_data %>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
)
patterns <- "\\bAI\\b|AI-|ChatGPT|OpenAI|Generative AI|\\bLLM\\b|\\bLLMs\\b|Large language models"
my_data_ai1 = my_data %>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
)
threshold <- as.Date("2022-11-30") + median(my_data$acceptance_delay)
my_data_ai2 = my_data_ai2 %>%
filter(article_date > threshold)
threshold <- as.Date("2022-11-30") + median(my_data$acceptance_delay)
my_data_ai2 = my_data_ai2 %>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
) %>%
filter(article_date > threshold)
my_data_ai2 = my_data%>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
) %>%
filter(article_date > threshold)
View(my_data_ai2)
my_data_control = my_data %>%
filter(article_date > threshold) %>%
semi_join(my_data_ai2, by = journal)
my_data_control = my_data %>%
filter(article_date > threshold) %>%
semi_join(my_data_ai2, by = journal)
my_data_control = my_data %>%
filter(article_date > threshold) %>%
semi_join(my_data_ai2, by = journal)
my_data_control = my_data %>%
filter(article_date > threshold) %>%
semi_join(my_data_ai2, by = "journal")
View(my_data_control)
my_data_ai2 %>%
summarise(journal)
levels(my_data_ai2$journal)
my_data_ai2 = my_data_ai2 %>%
mutate(journal = factor(journal))
levels(my_data_ai2$journal)
my_data_control= my_data_control %>%
mutate(journal = factor(journal))
levels(my_data_control$journal)
my_data_control = my_data %>%
filter(article_date > threshold) %>%
semi_join(my_data_ai2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
))
patterns <- "\\bAI\\b|\\bAI-|ChatGPT|OpenAI|Generative AI|\\bLLM\\b|\\bLLMs\\b|Large language models|Chat GPT|GPT-3.5|GPT-4"
my_data_ai1 = my_data %>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate|
article_date = as.Date(article_date)
article_date = as.Date(article_date)
my_data_ai1 = my_data %>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate
my_data_ai1 = my_data %>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate(article_date = as.Date(article_date))
threshold <- as.Date("2022-11-30") + median(my_data$acceptance_delay)
my_data_ai2 = my_data%>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
) %>%
filter(article_date > threshold)
my_data_control = my_data %>%
filter(article_date > threshold) %>%
semi_join(my_data_ai2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
))
my_data_ai2 = my_data_ai2 %>%
mutate(journal = factor(journal))
levels(my_data_ai2$journal)
my_data_control= my_data_control %>%
mutate(journal = factor(journal))
patterns <- "\\bAI\\b|\\bAI-|ChatGPT|OpenAI|Generative AI|\\bLLM\\b|\\bLLMs\\b|Large language models|Chat GPT|GPT-3.5|GPT-4|Generative artifical intelligence"
my_data_ai1 = my_data %>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate(article_date = as.Date(article_date))
threshold <- as.Date("2022-11-30") + median(my_data$acceptance_delay)
my_data_ai2 = my_data%>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
) %>%
filter(article_date > threshold)
my_data_control = my_data %>%
filter(article_date > threshold) %>%
semi_join(my_data_ai2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
))
my_data_ai2 = my_data_ai2 %>%
mutate(journal = factor(journal))
levels(my_data_ai2$journal)
my_data_control= my_data_control %>%
mutate(journal = factor(journal))
levels(my_data_control$journal)
my_data_ai1 %>%
ggplot()+
aes(x = article_date, y = acceptance_delay) %>%
geom_point()+
aes(x = article_date, y = acceptance_delay)+
geom_smooth()
my_data_ai2 %>%
ggplot()+
aes(x = article_date, y = acceptance_delay) %>%
geom_point()+
aes(x = article_date, y = acceptance_delay)+
geom_smooth()
patterns <- "\\bAI\\b|\\bAI-|ChatGPT|OpenAI|Generative AI|\\bLLM\\b|\\bLLMs\\b|Large language models|Chat GPT|GPT-3.5|GPT-4|\\bGPT\\b"
my_data_ai1 = my_data %>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate(article_date = as.Date(article_date))
threshold <- as.Date("2022-11-30") + median(my_data$acceptance_delay)
my_data_ai2 = my_data%>%
filter(
str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
) %>%
mutate(
article_date = as.Date(article_date)
) %>%
filter(article_date > threshold)
my_data_control = my_data %>%
filter(article_date > threshold) %>%
semi_join(my_data_ai2, by = "journal") %>%
filter(!( str_detect(title, regex(patterns, ignore_case = TRUE)) |
str_detect(keywords, regex(patterns, ignore_case = TRUE))
))
my_data_ai2 = my_data_ai2 %>%
mutate(journal = factor(journal))
levels(my_data_ai2$journal)
my_data_control= my_data_control %>%
mutate(journal = factor(journal))
levels(my_data_control$journal)
my_data_ai1 %>%
ggplot()+
aes(x = article_date, y = acceptance_delay) %>%
geom_point()+
aes(x = article_date, y = acceptance_delay)+
geom_smooth()
my_data_ai2 %>%
ggplot()+
aes(x = article_date, y = acceptance_delay) %>%
geom_point()+
aes(x = article_date, y = acceptance_delay)+
geom_smooth()
my_data_control %>%
ggplot()+
aes(x = article_date, y = acceptance_delay) %>%
geom_point()+
aes(x = article_date, y = acceptance_delay)+
geom_smooth()
my_data_control_sliced = my_data_control %>%
slice_sample(n = 527)
my_data_control_sliced %>%
ggplot()+
aes(x = article_date, y = acceptance_delay) %>%
geom_point()+
aes(x = article_date, y = acceptance_delay)+
geom_smooth()
my_data_ai2 %>%
ggplot()+
aes(x = article_date, y = acceptance_delay) %>%
geom_point()+
aes(x = article_date, y = acceptance_delay)+
geom_smooth()
t.test(my_data_ai2$acceptance_delay, my_data_control_sliced)
t.test(my_data_ai2$acceptance_delay, my_data_control_sliced$acceptance_delay)
View(my_data_control_sliced)
